<html>
<head>
  <title>Evernote Export</title>
  <basefont face="Tahoma" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/303788 (en-US, DDL); Windows/6.1.7601 Service Pack 1 (Win64);"/>
  <style>
    body, td {
      font-family: Tahoma;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="411"/>

<div>
<span><div>solver算是caffe的核心的核心，它协调着整个模型的运作。caffe程序运行必带的一个参数就是solver配置文件。运行代码一般为</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div># caffe train --solver=*_solver.prototxt</div></div><div><br/></div><div>在Deep Learning中，往往loss function是非凸的，没有解析解，我们要通过优化方法来求解。solve的主要作用就是交替调用前向(forward)算法和后向(backward)算法来更新参数，从而最小化loss，实际上就是一种迭代的优化算法。</div><div><br/></div><div>到目前为止，caffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置type类型来选择。</div><div><br/></div><ul><li>Stochastic Gradient Descent (type: &quot;SGD&quot;)</li><li>AdaDelta (type: &quot;AdaDelta&quot;)</li><li>Adaptive Gradient (type: &quot;AdaGrad&quot;)</li><li>Adam (type: &quot;Adam&quot;)</li><li>Nesterov's Accelerated Gradient (type: &quot;Nesterov&quot;)</li><li>RMSProp (type: &quot;RMSProp&quot;)</li></ul><div><br/></div><div>具体的每种方法的介绍，请看本系列的下一篇文章，本文着重介绍solver配置文件的编写。</div><div><br/></div><div>solver的流程：</div><div><br/></div><ol><li>设计好需要优化的对象，以及用于学习的训练网络和用于评估的测试网络。(通过调用另外一个配置文件prototxt来进行)</li><li>通过forward和backward迭代的进行优化来更新参数。</li><li>定期的评价测试网络。(可设定多少次训练后，进行一次测试)</li><li>在优化过程中显示模型和solver的状态。</li></ol><div><br/></div><div>在每一次的迭代过程中，solver做了这几步工作：</div><div><br/></div><ol><li>调用forward算法来计算最终的输出值，以及对应的loss</li><li>调用backward算法来计算每层的梯度</li><li>根据选用的solver方法，利用梯度进行参数更新</li><li>记录并保存每次迭代的学习率、快照，以及对应的状态</li></ol><div><br/></div><div>接下来，我们先来看一个示例：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>net: &quot;example/mnist/lenet_train_test.prototxt&quot;</div><div>test_iter: 100</div><div>test_interval: 500</div><div>base_lr: 0.01</div><div>momentum: 0.9</div><div>type: SGD</div><div>weight_decay: 0.0005</div><div>lr_policy: &quot;inv&quot;</div><div>gamma: 0.0001</div><div>power: 0.75</div><div>display: 100</div><div>max_iter: 20000</div><div>snapshot: 5000</div><div>snapshot_prefix: &quot;examples/mnist/lenet&quot;</div><div>solver_mode: CPU</div></div><div><br/></div><div>接下来，我们对每一行进行详细解释：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>net: &quot;examples/mnist/lenet_train_test.prototxt&quot;</div></div><div><br/></div><div>设置深度网络模型。每一个模型就是一个net，需要在一个专门的配置文件中对net进行配置，每个net由许多的layer组成。每一个layer的具体配置方式可参考本系列之前的文章。需要注意的是：文件的路径要从caffe的根目录开始，其他所有配置都是这样。</div><div><br/></div><div>也可用train_net和test_net来对训练模型和测试模型分别设定。例如：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>train_net: &quot;examples/hdf5_classification/logreg_auto_train.prototxt&quot;</div><div>test_net: &quot;examples/hdf5_classification/logreg_auto_test.prototxt&quot;<br/></div></div><div><br/></div><div>接下来，第二行：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>test_iter: 100</div></div><div><br/></div><div>这个要与test layer的batch_size结合起来理解。mnist数据中测试样本总数为10000，一次性执行全部数据效率很低，因此我们将测试数据分成几个批次来执行，每个批次的数量就是batch_size。假设我们设置batch_size为100，则需要迭代100次才能将10000个数据全部执行完。因此test_iter设置为100。执行完一次全部数据，称之为一个epoch。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>test_interval: 500</div></div><div><br/></div><div>测试间隔。也就是每训练500次，才进行一次测试。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>base_lr: 0.01</div><div>lr_policy: &quot;inv&quot;</div><div>gamma: 0.0001</div><div>power: 0.75</div></div><div><br/></div><div>这四行可以放在一起理解，用于学习率的设置。只要是梯度下降法来求解优化，都会有一个学习率，也叫步长。base_lr用于设置基础学习率，在迭代的过程中，可以对基础学习率进行调整。怎么样进行调整，就是调整的策略，由lr_policy来设置。</div><div><br/></div><div>lr_policy可以设置为下面这些值，相应的学习率的计算为：</div><div><br/></div><ul><li>fixed：保持base_lr不变。</li><li>step：如果设置为step，则还需要设置一个stepsize，返回base_lr * gamma ^ (floor(iter / stepsize))，其中iter表示当前的迭代次数。</li><li>exp：返回base_lr * gamma ^ iter，iter为当前迭代次数。</li><li>inv：如果设置为inv，还需要设置一个power，返回base_lr * (1 + gamma * iter) ^ (-power)</li><li>multistep：如果设置为multistep，则还需要设置一个stepvalue。这个参数和step很相似，step是均匀等间隔变化，而multistep则是根据stepvalue值变化。</li><li>poly：学习率进行多项式误差，返回base_lr * (1 - iter/max_iter) ^ (power)。</li><li>sigmoid：学习率进行sigmoid衰减，返回base_lr * (1 / (1 + exp(-gamma * (iter - stepsize))))。</li></ul><div><br/></div><div>multistep示例：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>base_lr: 0.01</div><div>momentum: 0.9</div><div>weight_decay: 0.0005</div><div># The learning rate policy.</div><div>lr_policy: &quot;multistep&quot;</div><div>gamma: 0.9</div><div>stepvalue: 5000</div><div>stepvalue: 7000</div><div>stepvalue: 8000</div><div>stepvalue: 9000</div><div>stepvalue: 9500<br/></div></div><div><br/></div><div>接下来的参数：</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>momentum: 0.9</div></div><div><br/></div><div>上一次梯度更新的权重，具体可参看下一篇文章。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>type: SGD</div></div><div><br/></div><div>优化算法选择。这一行可以省掉，因为默认值就是SGD。总共有六种方法可选择，在本文的开头已经介绍。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>weight_decay: 0.0005</div></div><div><br/></div><div>权重衰减项，防止过拟合的一个参数。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>display: 100</div></div><div><br/></div><div>每训练100次，在屏幕上显示一次。如果设置为0，则不显示。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>max_iter: 20000</div></div><div><br/></div><div>最大迭代次数。这个数设置太小，会导致没有收敛，精确度很低。设置太大，会导致震荡，浪费时间。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>snapshot: 5000</div><div>snapshot_prefix: &quot;examples/mnist/lenet&quot;</div></div><div><br/></div><div>快照。将训练出来的model和solver状态进行保存，snapshot用于设置训练多少次后进行保存，默认为0，不保存。snapshot_prefix设置保存路径。</div><div><br/></div><div>还可以设置snapshot_diff，是否保存梯度值，默认为false，不保存。</div><div><br/></div><div>也可以设置snapshot_format，保存的类型。有两种选择：HDF5和BINARYPROTO，默认为BINARYPROTO。</div><div><br/></div><div style="-en-codeblock: true; box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>solver_mode: CPU</div></div><div><br/></div><div>设置运行模式。默认为GPU，如果你没有GPU，则需要改成CPU，否则会出错。</div><div><br/></div><div>注意：以上所有的参数都是可选参数，都有默认值。根据solver方法(type)的不同，还有一些其他的参数，在此不一一列举。</div></span>
</div></body></html> 